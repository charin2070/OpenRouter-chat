# GoAI Timeline

## Project Concept
GoAI Timeline is an AIOps-powered tool designed to streamline incident analysis by automatically processing and visualizing data from logs, chats, and monitoring systems.

The core problem it solves is the "information noise" generated by modern IT systems, which can make finding the root cause of a failure a time-consuming and manual process. GoAI Timeline automates this by:

1.  **Aggregating Data**: It collects and normalizes logs, chat messages, and alerts from various sources into a single view.
2.  **Detecting Anomalies**: Using machine learning, it identifies unusual patterns and pinpoints anomalous events that are likely related to the incident.
3.  **Visualizing Incidents**: It displays the correlated events on an interactive timeline, providing a clear, chronological view of the incident. This helps teams quickly understand the sequence of events and identify the root cause (RCA).

This approach helps reduce mean time to resolution (MTTR), improves the efficiency of support teams, and provides valuable insights for preventing future incidents.

## Features
- 🔐 **Google Authentication**: Secure sign-in with Google OAuth
- 🤖 **Multi-AI Provider Support**: Choose between Google Gemma 3b and Mistral Medium models
- 🎛️ **AI Provider Selection**: Easy switching between AI providers via sidebar dropdown
- 💬 **Modern UI**: Clean, professional design with message bubbles and animations
- 📝 **Markdown Support**: Rich message rendering with GFM (lists, tables, checkboxes, code)
- ⚡ **Real-time Streaming**: See AI responses appear in real-time as they're generated
- 📱 **Responsive Design**: Works perfectly on desktop and mobile devices
- 🛡️ **Error Handling**: Graceful error handling with retry functionality
- 🧹 **Chat Management**: Clear chat history with confirmation dialog
- 👤 **User Profile**: Display user information and sign-out functionality
- ⌨️ **Keyboard Shortcuts**: Enter to send, Shift+Enter for new lines
- 🎨 **Professional Styling**: Beautiful gradients, animations, and micro-interactions

## Technology Stack
- **Framework**: Next.js 13.5.1 with App Router
- **Language**: TypeScript with strict type checking
- **Styling**: Tailwind CSS with shadcn/ui components
- **Authentication**: NextAuth.js with Google OAuth
- **AI Integration**: OpenRouter API, Mistral API
- **Package Manager**: pnpm (recommended) or npm

## TOP-10 THINGS ABOUT THIS PROJECT
1. Single source of truth: `README.md` is the entry point for debugging; always start with it.
2. Focus component: `QueryPanel` drives the core chat flow; start investigations there.
3. Multi-provider AI: Users can switch providers at runtime; the selection flows from UI state to backend routing.
4. Streaming-first UX: The system is optimized for streaming output for lower perceived latency.
5. Markdown-native chat: Messages support GFM Markdown safely (no raw HTML) with link hardening.
6. Robust error UX: Clear visual states and retry affordances across the stack.
7. Strong typing: TypeScript everywhere with shared types to avoid drift.
8. Auth-gated app: Google OAuth is mandatory; local dev requires proper OAuth setup.
9. Performance hygiene: Memoization, trimmed bundle, and Tailwind utility approach for lean UI.
10. Extensibility: Clear component boundaries (sidebar, header, message list/bubble) and hook-based chat logic enable quick feature additions.

## TOP-10 THINGS ABOUT UI
1. App Router UI: Next.js 13 App Router with React 18 and client/server components; main chat lives in `app/page.tsx` via `QueryPanel`.
2. QueryPanel is the hub: Most user actions (send, edit, repeat, provider switch, shortcuts) originate from `QueryPanel` and its hooks.
3. Message rendering: `components/chat/message-bubble.tsx` renders bubbles; supports Markdown via `react-markdown` + `remark-gfm` with safe links and styled lists/code.
4. Message status UX: Single check = sending, double check = sent, alert = error; timestamps shown; user action buttons (repeat, edit) under user messages.
5. Sidebar controls: AI provider dropdown in `components/chat/sidebar.tsx` and `ai-provider-dropdown.tsx`; selection persists during session.
6. UI toolkit: Tailwind CSS + shadcn/ui (Radix) components; consistent theming via global styles in `app/globals.css` and utility `cn`.
7. Responsive design: Mobile-first, scrollable `message-list`, touch-friendly hit areas, keyboard support (Enter send, Shift+Enter newline).
8. Streaming UI: AI responses stream into bubbles in real time; smooth animations and micro-interactions for feedback.
9. Error states: Graceful UI for network/API errors with retry; AI error bubbles highlighted with red accents.
10. Avatars and identity: User avatar via Google profile (when available), AI fallback badge; clear visual alignment (user right, AI left).

## TOP-10 THINGS ABOUT BACKEND
1. Auth: NextAuth.js with Google OAuth; required envs `GOOGLE_CLIENT_ID`, `GOOGLE_CLIENT_SECRET`, `NEXTAUTH_SECRET`, `NEXTAUTH_URL`.
2. API routing: App Router API endpoints under `app/api/` including `auth/[...nextauth]/` and chat endpoint for AI requests.
3. AI providers: OpenRouter gateway supports Google Gemma and Mistral; selected provider is sent from client and validated server-side.
4. Streaming responses: Backend returns streaming chunks consumed by UI for real-time rendering.
5. Config via env: Keys and model params (`OPENROUTER_API_KEY`, `AI_MISTRAL_MODEL`, `AI_TEMPERATURE`, `AI_MAX_TOKENS`) configured via `.env.local`.
6. Security posture: API keys server-side only; JWT sessions; input validated; rate-limiting considerations in endpoints.
7. Provider abstraction: Unified request/response shape regardless of underlying model; backend routes to appropriate provider.
8. Error handling: Backend surfaces typed errors consumed by UI to display retries and error states.
9. Types: Shared types in `lib/types.ts` standardize message, role, status across client/server.
10. Deployment: Standard Next build/start; environment variables required at runtime; compatible with Vercel hosting.


## TOP-3 Tips
1. **README.md - entry point for all dubug sessions** - only critical information about project context is stored here. Use it and keep up to date.
2. **99% actions user requests from QueryPanel component** - this component is the main component of the application and is responsible for the main functionality of the application. Always start debugging from this component.
3. **UI structure** - main UI components: 
   Chat
   Settings window

## Getting Started

### Prerequisites
- Node.js 18+ 
- pnpm (recommended) or npm
- OpenRouter API key
- Mistral API key

### Installation
1. Clone the repository:
   git clone https://github.com/charin2070/goai-timeline
   cd goai-timeline

2. Install dependencies:
   pnpm install

3. Set up environment variables:
   - Copy `.env.local` and update if needed

4. Start the development server:
   pnpm redev

### Alternative Development Commands
# Standard development server
pnpm dev

# Build for production
pnpm build

# Start production server
pnpm start

## Project Structure
```
├── app/
├── documentation/ # Project documentation and guides
├── lib/ # Shared libraries and utilities
├── public/ # Static assets
├── components/ # Reusable components
├── hooks/ # Custom hooks
├── api/ # API routes
│   ├── auth/[...nextauth]/ # NextAuth API routes
│   │   └── chat/          # API route for OpenRouter communication
│   ├── globals.css        # Global styles and Tailwind CSS
│   ├── layout.tsx         # Root layout with metadata
│   └── page.tsx           # Main page
├── components/
│   ├── auth/              # Authentication components
│   │   ├── sign-in.tsx    # Google Sign-In component
│   │   └── user-profile.tsx # User profile dropdown
│   ├── chat/              # Chat-specific components
│   │   ├── chat-header.tsx     # Header with clear chat functionality
│   │   ├── sidebar.tsx         # Sidebar with AI provider selection
│   │   ├── message-list.tsx    # Scrollable message container
│   │   ├── message-bubble.tsx  # Individual message bubbles
│   │   ├── message-input.tsx   # Input field with send button
│   │   ├── error-message.tsx   # Error display with retry
│   │   └── log-uploader.tsx    # Log file upload component
│   └── ui/                # shadcn/ui components
├── hooks/
│   └── use-chat.ts        # Custom hook for chat functionality
├── lib/
│   ├── auth-context.tsx   # Authentication context
│   ├── types.ts           # TypeScript interfaces and AI provider configurations
│   ├── openrouter.ts      # OpenRouter API integration with multi-provider support
│   ├── mistral.ts         # Mistral API integration (alternative provider)
│   └── utils.ts           # Utility functions
└── .env.local             # Environment variables
```

## Key Features Explained

### Multi-AI Provider Support
The application supports multiple AI providers, allowing users to choose the best model for their needs:
- **Google Gemma 3b**: Fast and efficient model for general conversation (Free tier)
- **Mistral Medium**: Advanced model with enhanced reasoning capabilities (Premium tier)
- **Easy Switching**: Users can switch between providers using the sidebar dropdown
- **Provider Persistence**: Selected provider is maintained during the session
- **Unified Interface**: All providers use the same chat interface and streaming responses

### Google Authentication
The application uses NextAuth.js with Google OAuth for secure user authentication:
- **Sign In**: Users can sign in with their Google account
- **Session Management**: Automatic session handling and persistence
- **User Profile**: Display user information and sign-out functionality
- **Protected Routes**: Chat interface is only accessible to authenticated users

### Streaming Responses
The application uses Server-Sent Events (SSE) to stream AI responses in real-time, providing a smooth chat experience.

### Message Status Indicators
Each message shows its status:
- **Sending**: Single check mark (gray)
- **Sent**: Double check mark (blue)  
- **Error**: Alert circle (red)

### Error Handling
- Network errors are caught and displayed with retry options
- API errors show user-friendly messages
- Graceful degradation when streaming fails

### Responsive Design
- Mobile-first design approach
- Adaptive message bubble sizes
- Touch-friendly interface elements
- Proper keyboard navigation

## Environment Variables
Create a `.env.local` file in the root directory with the following variables:

### Environment Variables Explained
- **OPENROUTER_API_KEY**: Your OpenRouter API key for AI model access (supports both Google Gemma and Mistral)
- **AI_MISTRAL_MODEL**: Mistral model identifier (default: `mistralai/mistral-medium`)
- **AI_TEMPERATURE**: Controls response randomness (default: 0.7)
- **AI_MAX_TOKENS**: Maximum tokens in response (default: 1000)
- **NEXT_PUBLIC_APP_NAME**: The name of your application (displayed in UI)
- **NEXT_PUBLIC_APP_URL**: The base URL of your application
- **NEXT_PUBLIC_SPINNER_SPEED**: Speed of Tetris spinner animation in milliseconds (default: 300ms)
- **GOOGLE_CLIENT_ID**: Google OAuth client ID for authentication
- **GOOGLE_CLIENT_SECRET**: Google OAuth client secret for authentication
- **NEXTAUTH_SECRET**: Secret key for NextAuth.js session encryption
- **NEXTAUTH_URL**: The base URL for NextAuth.js callbacks

### Setting up Google OAuth

1. Go to the [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select an existing one
3. Enable the Google+ API (or Google Identity API)
4. Go to "Credentials" and create an "OAuth 2.0 Client ID"
5. Set the authorized redirect URI to: `http://localhost:3000/api/auth/callback/google`
6. Copy the Client ID and Client Secret to your `.env.local` file

### Generating NextAuth Secret

You can generate a secure secret using:
```bash
openssl rand -base64 32
```

### Complete Setup Steps

1. **Install dependencies**:
   ```bash
   pnpm install
   ```

2. **Set up environment variables**:
   - Copy the example environment variables above
   - Create a `.env.local` file in the root directory
   - Add your Google OAuth credentials and NextAuth secret

3. **Start the development server**:
   ```bash
   pnpm dev
   ```

4. **Access the application**:
   - Open `http://localhost:3000`
   - You'll be redirected to the sign-in page
   - Click "Sign in with Google" to authenticate
   - After successful authentication, you'll be redirected to the chat interface

5. **Choose your AI provider**:
   - Use the dropdown in the sidebar to select between Google Gemma 3b and Mistral Medium
   - The selected provider will be used for all subsequent chat messages
   - You can switch providers at any time during your session

## Security Considerations
- **Authentication**: Secure OAuth 2.0 flow with Google
- **Session Management**: JWT tokens with secure storage
- **API Security**: API keys are stored server-side only
- **Rate Limiting**: Considerations implemented for API endpoints
- **Input Validation**: Validation on all API endpoints
- **Error Handling**: Secure error handling without exposing internals
- **Environment Variables**: Sensitive data stored in environment variables

## AI Provider Selection
The application supports multiple AI providers through a unified interface:

### Technical Implementation
- Provider state is managed in the `useChat` hook
- API requests include the selected provider parameter
- Backend validates and routes requests to the appropriate model
- All providers use the same streaming response format

## Performance Optimizations
- Proper memoization of components
- Optimized bundle size with Next.js
- Streaming responses to reduce perceived latency

## Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add appropriate tests
5. Submit a pull request

## Guides
- Как добавить Markdown: [app/documentation/Как добавить markdown.md](app/documentation/%D0%9A%D0%B0%D0%BA%20%D0%B4%D0%BE%D0%B1%D0%B0%D0%B2%D0%B8%D1%82%D1%8C%20markdown.md)

## License
This project is licensed under the MIT License. See LICENSE file for details.